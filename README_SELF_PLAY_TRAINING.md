# Self-Play Training Pipeline - Operations Guide

## üéØ Overview

The Self-Play Training Pipeline is a comprehensive, production-grade system for autonomous neural network evolution in Battlesnake AI. It implements a sophisticated multi-phase training approach that enables continuous improvement through self-play, statistical validation, and automated model evolution.

### Key Features

- **Multi-Phase Training**: Bootstrap ‚Üí Hybrid ‚Üí Self-Play ‚Üí Continuous learning progression
- **Autonomous Operation**: 24/7 automated training with intelligent scheduling and triggers
- **Statistical Rigor**: Confidence intervals, significance testing, and performance validation
- **Production Integration**: ONNX export for seamless Rust deployment (<10ms inference, <50MB memory)
- **Comprehensive Monitoring**: Real-time metrics, resource tracking, and automated alerts
- **Fault Tolerance**: Error recovery, rollback mechanisms, and graceful degradation

## üìã Quick Start

### Prerequisites

```bash
# Required Python packages
pip install torch torchvision numpy pandas scikit-learn
pip install schedule croniter psutil sqlite3
pip install onnxruntime onnx

# System requirements
- Python 3.8+
- 8GB+ RAM recommended
- 20GB+ free disk space
- CUDA-compatible GPU (optional but recommended)
```

### Basic Setup

1. **Initialize Configuration**:
```bash
python -c "from config.self_play_config import get_config; get_config().save_to_file('my_config.json')"
```

2. **Start Training Pipeline**:
```python
from self_play_training_pipeline import SelfPlayTrainingPipeline, TrainingConfiguration

# Basic training configuration
config = TrainingConfiguration(
    target_phases=["bootstrap", "hybrid", "self_play"],
    continuous_learning_enabled=True,
    max_training_time_hours=6
)

# Initialize and run pipeline
pipeline = SelfPlayTrainingPipeline()
success = pipeline.run_complete_pipeline(config)
print(f"Training {'completed' if success else 'failed'}")
```

3. **Start Automated Runner** (Optional - for 24/7 operation):
```python
from automated_training_runner import AutomatedTrainingRunner, create_default_schedules

runner = AutomatedTrainingRunner()

# Add default schedules (daily, weekly, continuous)
for schedule in create_default_schedules():
    runner.add_schedule(schedule)

# Start automation
runner.start_automation()
print("Automated training started - running 24/7")
```

## üîß Architecture Overview

### Core Components

```
Self-Play Training Pipeline
‚îú‚îÄ‚îÄ Configuration System (config/self_play_config.py)
‚îÇ   ‚îú‚îÄ‚îÄ Training phase configurations
‚îÇ   ‚îú‚îÄ‚îÄ Neural network architectures
‚îÇ   ‚îú‚îÄ‚îÄ Tournament settings
‚îÇ   ‚îî‚îÄ‚îÄ Pipeline parameters
‚îÇ
‚îú‚îÄ‚îÄ Data Management (self_play_data_manager.py)
‚îÇ   ‚îú‚îÄ‚îÄ Game data processing
‚îÇ   ‚îú‚îÄ‚îÄ Experience replay buffers
‚îÇ   ‚îú‚îÄ‚îÄ Quality-based sampling
‚îÇ   ‚îî‚îÄ‚îÄ Training data pipeline
‚îÇ
‚îú‚îÄ‚îÄ Model Evolution (model_evolution.py)
‚îÇ   ‚îú‚îÄ‚îÄ Multi-phase training system
‚îÇ   ‚îú‚îÄ‚îÄ Tournament management
‚îÇ   ‚îú‚îÄ‚îÄ Model registry
‚îÇ   ‚îî‚îÄ‚îÄ Performance tracking
‚îÇ
‚îú‚îÄ‚îÄ Performance Evaluation (model_performance_evaluator.py)
‚îÇ   ‚îú‚îÄ‚îÄ Statistical validation
‚îÇ   ‚îú‚îÄ‚îÄ Benchmark testing
‚îÇ   ‚îú‚îÄ‚îÄ Production readiness validation
‚îÇ   ‚îî‚îÄ‚îÄ Strategic analysis
‚îÇ
‚îú‚îÄ‚îÄ Training Orchestrator (self_play_training_pipeline.py)
‚îÇ   ‚îú‚îÄ‚îÄ Pipeline coordination
‚îÇ   ‚îú‚îÄ‚îÄ State management
‚îÇ   ‚îú‚îÄ‚îÄ Progress monitoring
‚îÇ   ‚îî‚îÄ‚îÄ Error recovery
‚îÇ
‚îî‚îÄ‚îÄ Automated Runner (automated_training_runner.py)
    ‚îú‚îÄ‚îÄ Cron-based scheduling
    ‚îú‚îÄ‚îÄ Intelligent triggers
    ‚îú‚îÄ‚îÄ Resource management
    ‚îî‚îÄ‚îÄ Notification system
```

### Training Phase Progression

```
1. Bootstrap Phase
   ‚îú‚îÄ‚îÄ Heuristic supervision data collection
   ‚îú‚îÄ‚îÄ Initial neural network training
   ‚îú‚îÄ‚îÄ Basic strategy learning
   ‚îî‚îÄ‚îÄ Foundation model creation

2. Hybrid Phase
   ‚îú‚îÄ‚îÄ Mixed heuristic + neural training
   ‚îú‚îÄ‚îÄ Strategy refinement
   ‚îú‚îÄ‚îÄ Performance improvement
   ‚îî‚îÄ‚îÄ Transition preparation

3. Self-Play Phase
   ‚îú‚îÄ‚îÄ Neural vs neural games
   ‚îú‚îÄ‚îÄ Strategic depth development
   ‚îú‚îÄ‚îÄ Advanced pattern recognition
   ‚îî‚îÄ‚îÄ Elite model evolution

4. Continuous Phase
   ‚îú‚îÄ‚îÄ Ongoing improvement
   ‚îú‚îÄ‚îÄ Performance monitoring
   ‚îú‚îÄ‚îÄ Adaptive learning
   ‚îî‚îÄ‚îÄ Production model updates
```

## ‚öôÔ∏è Configuration

### Training Configuration

```python
from self_play_training_pipeline import TrainingConfiguration

# Comprehensive training
full_config = TrainingConfiguration(
    target_phases=["bootstrap", "hybrid", "self_play", "continuous"],
    continuous_learning_enabled=True,
    max_training_time_hours=12,
    force_retrain=False,
    enable_monitoring=True,
    save_checkpoints=True,
    export_onnx=True
)

# Quick training (testing)
quick_config = TrainingConfiguration(
    target_phases=["bootstrap"],
    max_training_time_hours=1,
    enable_monitoring=False
)

# Continuous learning only
continuous_config = TrainingConfiguration(
    target_phases=["continuous"],
    continuous_learning_enabled=True,
    max_training_time_hours=2
)
```

### Neural Network Configuration

```python
from config.self_play_config import NeuralNetworkConfig

# High-performance configuration
nn_config = NeuralNetworkConfig(
    architecture_type="CNN_Attention_Residual",
    input_channels=12,  # 12-channel board encoding
    hidden_layers=[512, 256, 128],
    attention_heads=8,
    residual_connections=True,
    dropout_rate=0.1,
    batch_norm=True
)

# Lightweight configuration (faster training)
lightweight_config = NeuralNetworkConfig(
    architecture_type="CNN_Simple",
    hidden_layers=[256, 128],
    attention_heads=4,
    dropout_rate=0.2
)
```

### Automated Runner Configuration

```python
from automated_training_runner import TrainingSchedule, TriggerCondition, TriggerType

# Daily comprehensive training
daily_schedule = TrainingSchedule(
    name="daily_full_training",
    cron_expression="0 2 * * *",  # 2 AM every day
    training_config=full_config,
    max_duration_hours=8,
    min_data_threshold=1000,  # Require 1000+ new games
    notification_emails=["admin@battlesnake.com"]
)

# Data-driven trigger
data_trigger = TriggerCondition(
    name="high_data_availability",
    trigger_type=TriggerType.DATA_DRIVEN,
    condition_function="check_new_data_threshold",
    parameters={"min_games": 5000},
    cooldown_hours=12
)
```

## üöÄ Operations

### Starting Training

#### Manual Training Execution

```python
from self_play_training_pipeline import SelfPlayTrainingPipeline

# Initialize pipeline
pipeline = SelfPlayTrainingPipeline()

# Run complete training cycle
success = pipeline.run_complete_pipeline(config)

# Monitor progress
status = pipeline.get_pipeline_status()
print(f"Status: {status.status}")
print(f"Phase: {status.current_phase}")
print(f"Models Trained: {status.total_models_trained}")
print(f"Best Win Rate: {status.best_win_rate*100:.1f}%")
```

#### Automated Training (24/7 Operation)

```python
from automated_training_runner import AutomatedTrainingRunner

# Initialize runner
runner = AutomatedTrainingRunner()

# Add schedules
runner.add_schedule(daily_schedule)
runner.add_schedule(weekly_schedule)
runner.add_trigger(data_trigger)

# Start automation
runner.start_automation()

# Monitor status
status = runner.get_runner_status()
print(f"Runner Status: {status['status']}")
print(f"Active Schedules: {len(status['schedules'])}")
print(f"Recent Executions: {len(status['recent_executions'])}")
```

### Monitoring and Control

#### Real-time Monitoring

```python
import time

# Monitor pipeline progress
while pipeline.get_pipeline_status().status != PipelineStatus.COMPLETED:
    status = pipeline.get_pipeline_status()
    print(f"Phase: {status.current_phase}, Progress: {status.progress_percentage:.1f}%")
    time.sleep(30)

# Monitor automated runner
runner_status = runner.get_runner_status()
if runner_status['current_execution']:
    exec_info = runner_status['current_execution']
    print(f"Currently running: {exec_info['schedule_name']}")
    print(f"Started: {exec_info['started_at']}")
```

#### Performance Metrics

```python
from model_performance_evaluator import ModelPerformanceEvaluator

evaluator = ModelPerformanceEvaluator()

# Get champion model performance
champion_metrics = evaluator.get_champion_performance()
print(f"Champion Win Rate: {champion_metrics['win_rate']*100:.1f}%")
print(f"Strategic Score: {champion_metrics['strategic_score']:.1f}")
print(f"Production Ready: {champion_metrics['production_ready']}")

# Get evaluation history
history = evaluator.get_evaluation_history()
for eval_result in history[-5:]:  # Last 5 evaluations
    print(f"Model: {eval_result.model_name}, Win Rate: {eval_result.win_rate:.3f}")
```

### Control Commands

```python
# Pause automation
runner.pause_automation()

# Resume automation
runner.resume_automation()

# Stop automation gracefully
runner.stop_automation()

# Emergency stop with cleanup
pipeline.emergency_stop()

# Manual trigger
trigger_file = Path("trigger_training.txt")
trigger_file.touch()  # Will trigger training on next check
```

## üìä Data Management

### Game Data Integration

The pipeline integrates with the existing Phase 8 data collection system:

```python
# Collect training data
data_manager = SelfPlayDataManager()

# Heuristic supervision data (bootstrap phase)
heuristic_data = data_manager.collect_heuristic_supervision_data(
    target_games=10000,
    parallel_processes=8
)

# Self-play data (advanced phases)
self_play_data = data_manager.collect_self_play_data(
    model_pairs=[("champion", "challenger")],
    games_per_pair=1000,
    parallel_processes=12
)

# Data statistics
stats = data_manager.get_data_statistics()
print(f"Total Games: {stats['total_games']}")
print(f"Training Samples: {stats['total_samples']}")
print(f"Data Quality Score: {stats['average_quality_score']:.2f}")
```

### Experience Replay Management

```python
# Configure experience replay
from self_play_data_manager import ExperienceReplayBuffer

buffer = ExperienceReplayBuffer(
    max_size=100000,  # 100k experiences
    quality_threshold=0.6,  # Keep only high-quality experiences
    prioritized_sampling=True
)

# Sample training batches
training_batch = buffer.sample_batch(batch_size=256)
high_quality_batch = buffer.sample_high_quality_batch(batch_size=64)
```

## üß† Model Management

### Model Evolution

```python
from model_evolution import ModelEvolutionSystem

evolution = ModelEvolutionSystem()

# Bootstrap training
bootstrap_model = evolution.bootstrap_training_phase(
    target_games=5000,
    training_epochs=20
)

# Hybrid training
hybrid_model = evolution.hybrid_training_phase(
    base_model=bootstrap_model,
    heuristic_ratio=0.3,  # 30% heuristic, 70% neural
    training_epochs=30
)

# Tournament evaluation
tournament_results = evolution.run_model_tournament(
    models={"champion": champion_model, "challenger": hybrid_model},
    games_per_matchup=200
)
```

### Model Registry

```python
from model_evolution import ModelRegistry

registry = ModelRegistry()

# Register new model
model_id = registry.register_model(
    model=new_model,
    model_info={
        'name': 'advanced_v2.1',
        'architecture': 'CNN_Attention_Residual',
        'training_phase': 'self_play',
        'performance_metrics': {
            'win_rate': 0.73,
            'strategic_score': 87.5,
            'inference_time_ms': 4.2
        }
    }
)

# Retrieve model
model, info = registry.get_model(model_id)

# List available models
models = registry.list_models()
for model_info in models:
    print(f"Model: {model_info['name']}, Win Rate: {model_info['performance_metrics']['win_rate']:.3f}")
```

### ONNX Export for Production

```python
# Export champion model to ONNX for Rust integration
onnx_path = evolution.export_champion_to_onnx(
    output_path="models/champion.onnx",
    optimize=True,
    validate_inference_time=True  # Must be <10ms
)

print(f"Champion model exported to: {onnx_path}")

# Validate production readiness
from model_performance_evaluator import PerformanceBenchmark

benchmark = PerformanceBenchmark()
is_ready, metrics = benchmark.validate_production_readiness(
    champion_model,
    max_inference_time_ms=10,
    max_memory_mb=50
)

print(f"Production Ready: {is_ready}")
print(f"Inference Time: {metrics['inference_time_ms']:.1f}ms")
print(f"Memory Usage: {metrics['memory_usage_mb']:.1f}MB")
```

## üîç Monitoring and Debugging

### Comprehensive Logging

```python
import logging

# Enable detailed logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training_pipeline.log'),
        logging.StreamHandler()
    ]
)

# Component-specific logging levels
logging.getLogger('model_evolution').setLevel(logging.DEBUG)
logging.getLogger('automated_training_runner').setLevel(logging.INFO)
```

### Performance Monitoring

```python
# Real-time system monitoring
import psutil
import time

def monitor_resources():
    while pipeline.is_training():
        # System resources
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('.')
        
        print(f"CPU: {cpu_percent:.1f}%, RAM: {memory.percent:.1f}%, Disk: {disk.percent:.1f}%")
        
        # GPU monitoring (if available)
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated() * 100
            print(f"GPU Memory: {gpu_memory:.1f}%")
        
        time.sleep(60)
```

### Error Handling and Recovery

```python
# Automatic error recovery
try:
    success = pipeline.run_complete_pipeline(config)
except Exception as e:
    print(f"Training failed: {e}")
    
    # Attempt recovery
    recovery_success = pipeline.attempt_recovery()
    if recovery_success:
        print("Recovery successful, resuming training")
        success = pipeline.resume_training()
    else:
        print("Recovery failed, manual intervention required")
        
        # Rollback to last stable state
        pipeline.rollback_to_checkpoint()
```

### Database Queries

```python
import sqlite3

# Query training history
def get_training_history():
    with sqlite3.connect('automation/automation_tracking.db') as conn:
        cursor = conn.execute("""
            SELECT schedule_name, started_at, completed_at, success, 
                   json_extract(pipeline_state_json, '$.best_win_rate') as win_rate
            FROM executions 
            ORDER BY started_at DESC 
            LIMIT 10
        """)
        
        for row in cursor.fetchall():
            print(f"Schedule: {row[0]}, Success: {row[3]}, Win Rate: {row[4]:.3f}")

# Query schedule statistics
def get_schedule_stats():
    with sqlite3.connect('automation/automation_tracking.db') as conn:
        cursor = conn.execute("""
            SELECT schedule_name, run_count, success_count, 
                   CAST(success_count AS FLOAT) / run_count as success_rate
            FROM schedule_runs 
            ORDER BY run_count DESC
        """)
        
        for row in cursor.fetchall():
            print(f"Schedule: {row[0]}, Runs: {row[1]}, Success Rate: {row[3]:.3f}")
```

## üö® Troubleshooting

### Common Issues

#### 1. Training Stuck or Slow

**Symptoms**: Training progress stops or is very slow
```python
# Check system resources
import psutil
print(f"CPU: {psutil.cpu_percent()}%, Memory: {psutil.virtual_memory().percent}%")

# Check data availability
stats = data_manager.get_data_statistics()
if stats['total_games'] < 1000:
    print("Insufficient training data - collect more games")

# Check model complexity
if config.neural_network.hidden_layers == [512, 512, 512]:
    print("Model too complex - reduce layer sizes for faster training")
```

**Solutions**:
- Reduce batch size: `config.training_phases['bootstrap'].batch_size = 32`
- Use lighter model: `config.neural_network.hidden_layers = [256, 128]`
- Enable gradient accumulation: `config.training_phases['bootstrap'].gradient_accumulation_steps = 4`

#### 2. Memory Issues

**Symptoms**: Out of memory errors, system freeze
```python
# Monitor memory usage
def check_memory_usage():
    process = psutil.Process()
    memory_info = process.memory_info()
    print(f"Process memory: {memory_info.rss / 1024 / 1024:.1f} MB")
    
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3
        print(f"GPU memory: {gpu_memory:.1f} GB")
```

**Solutions**:
- Reduce batch size: `batch_size = 16`
- Clear GPU cache: `torch.cuda.empty_cache()`
- Use gradient checkpointing: `gradient_checkpointing = True`
- Reduce experience buffer size: `max_size = 50000`

#### 3. Poor Model Performance

**Symptoms**: Low win rates, no improvement over baseline
```python
# Analyze model performance
champion_metrics = evaluator.get_champion_performance()
if champion_metrics['win_rate'] < 0.6:
    print("Performance below threshold - check training data quality")
    
    # Analyze data quality
    quality_stats = data_manager.get_data_quality_analysis()
    print(f"Average game length: {quality_stats['avg_game_length']}")
    print(f"Strategic diversity: {quality_stats['strategy_diversity']}")
```

**Solutions**:
- Increase training data: `target_games = 20000`
- Improve data quality: `quality_threshold = 0.8`
- Extend training: `training_epochs = 50`
- Tune hyperparameters: `learning_rate = 0.0001`

#### 4. Automation Issues

**Symptoms**: Scheduled training not running, triggers not firing
```python
# Check runner status
status = runner.get_runner_status()
print(f"Runner status: {status['status']}")
print(f"Running: {status['running']}")
print(f"Paused: {status['paused']}")

# Check schedule syntax
import croniter
try:
    cron = croniter.croniter("0 2 * * *")  # Check cron expression
    print(f"Next run: {cron.get_next(datetime)}")
except ValueError as e:
    print(f"Invalid cron expression: {e}")
```

**Solutions**:
- Restart automation: `runner.stop_automation(); runner.start_automation()`
- Check resource requirements: Lower `min_free_memory_gb = 2`
- Verify trigger conditions: Check `min_games` threshold
- Review logs: Check `automation/logs/runner_*.log`

### Debug Commands

```python
# Enable debug mode
pipeline.enable_debug_mode()
runner.enable_debug_logging()

# Force training execution
runner._execute_scheduled_training("debug_training", debug_schedule)

# Manual tournament
tournament_results = evolution.run_manual_tournament(
    models={"model_a": model_a, "model_b": model_b},
    games=100,
    verbose=True
)

# Export debug information
debug_info = {
    'pipeline_state': pipeline.get_pipeline_status(),
    'data_stats': data_manager.get_data_statistics(),
    'system_info': {
        'cpu_count': psutil.cpu_count(),
        'memory_gb': psutil.virtual_memory().total / 1024**3,
        'cuda_available': torch.cuda.is_available()
    }
}

with open('debug_info.json', 'w') as f:
    json.dump(debug_info, f, indent=2, default=str)
```

## üéØ Advanced Usage

### Custom Training Phases

```python
# Create custom training phase
custom_phase_config = TrainingPhaseConfig(
    learning_rate=0.0005,
    batch_size=64,
    max_epochs=25,
    early_stopping_patience=8,
    validation_split=0.15,
    data_augmentation=True
)

# Add to pipeline
pipeline.config.training_phases['custom_phase'] = custom_phase_config
```

### Custom Evaluation Metrics

```python
# Define custom evaluation function
def custom_strategic_analysis(game_results):
    """Custom strategic analysis for game results"""
    strategic_metrics = {}
    
    # Calculate advanced metrics
    for game in game_results:
        # Territory control analysis
        # Food efficiency analysis
        # Trap avoidance analysis
        pass
    
    return strategic_metrics

# Register custom evaluator
evaluator.register_custom_analysis_function(custom_strategic_analysis)
```

### Integration with External Systems

```python
# Custom notification system
class SlackNotificationSystem:
    def send_training_completion_notification(self, result):
        # Send Slack notification
        pass

# Replace notification system
runner.notification_system = SlackNotificationSystem()

# Custom data source
class CustomDataSource:
    def collect_game_data(self, num_games):
        # Collect from custom source
        pass

# Use custom data source
data_manager.add_data_source(CustomDataSource())
```

### Performance Optimization

```python
# Multi-GPU training
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
    config.neural_network.use_multi_gpu = True

# Distributed training setup
import torch.distributed as dist
if dist.is_available():
    dist.init_process_group(backend='nccl')
    model = nn.parallel.DistributedDataParallel(model)

# Mixed precision training
from torch.cuda.amp import GradScaler, autocast
scaler = GradScaler()
config.training_optimization.use_mixed_precision = True
```

## üîÑ Integration with Existing Systems

### Phase 8 Data Collection Integration

```python
# Use existing data collection system
from data_collection import BattlesnakeDataCollector

# Integrate with self-play pipeline
data_collector = BattlesnakeDataCollector()
collected_games = data_collector.collect_batch_games(
    num_games=10000,
    game_config={'width': 11, 'height': 11, 'timeout': 500}
)

# Process for training
data_manager.import_external_games(collected_games)
```

### Phase 9 Neural Network Integration

```python
# Load existing Phase 9 models
from neural_models import load_champion_model

existing_champion = load_champion_model('models/phase9_champion.onnx')

# Use as bootstrap model
evolution.set_bootstrap_model(existing_champion)

# Continue evolution from existing model
advanced_model = evolution.evolve_from_existing(
    base_model=existing_champion,
    target_improvement=0.1  # 10% win rate improvement
)
```

### Rust Production Integration

```bash
# Export models for Rust integration
python -c "
from model_evolution import ModelEvolutionSystem
evo = ModelEvolutionSystem()
evo.export_production_models('models/production/')
"

# Update Rust configuration
cp models/production/champion.onnx src/models/
cargo build --release
```

## üìà Scaling and Production Deployment

### Horizontal Scaling

```python
# Multi-machine setup
from automated_training_runner import DistributedTrainingRunner

# Master node
master_runner = DistributedTrainingRunner(node_type='master')
master_runner.start_cluster()

# Worker nodes
worker_runner = DistributedTrainingRunner(
    node_type='worker',
    master_address='192.168.1.100:5000'
)
worker_runner.join_cluster()
```

### Cloud Deployment

```yaml
# docker-compose.yml
version: '3.8'
services:
  training-pipeline:
    build: .
    volumes:
      - ./models:/app/models
      - ./data:/app/data
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - TRAINING_MODE=automated
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

### Kubernetes Deployment

```yaml
# k8s-training-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: battlesnake-training
spec:
  template:
    spec:
      containers:
      - name: training-pipeline
        image: battlesnake-ai/training-pipeline:latest
        resources:
          requests:
            nvidia.com/gpu: 1
            memory: "8Gi"
            cpu: "4"
          limits:
            nvidia.com/gpu: 1
            memory: "16Gi"
            cpu: "8"
        env:
        - name: TRAINING_CONFIG
          value: "production"
```

## üìö API Reference

### Core Classes

#### SelfPlayTrainingPipeline

```python
class SelfPlayTrainingPipeline:
    def __init__(self, config_manager=None)
    def run_complete_pipeline(self, config: TrainingConfiguration) -> bool
    def get_pipeline_status(self) -> PipelineStatus
    def start_monitoring(self) -> None
    def stop_monitoring(self) -> None
    def emergency_stop(self) -> None
```

#### AutomatedTrainingRunner

```python
class AutomatedTrainingRunner:
    def __init__(self, config_manager=None)
    def add_schedule(self, schedule: TrainingSchedule) -> None
    def add_trigger(self, trigger: TriggerCondition) -> None
    def start_automation(self) -> None
    def stop_automation(self) -> None
    def get_runner_status(self) -> Dict[str, Any]
```

#### ModelEvolutionSystem

```python
class ModelEvolutionSystem:
    def bootstrap_training_phase(self, target_games: int, training_epochs: int)
    def hybrid_training_phase(self, base_model, heuristic_ratio: float)
    def self_play_training_phase(self, models: Dict[str, Any])
    def get_evolution_status(self) -> Dict[str, Any]
```

### Configuration Objects

```python
@dataclass
class TrainingConfiguration:
    target_phases: List[str]
    continuous_learning_enabled: bool
    max_training_time_hours: int
    force_retrain: bool = False
    enable_monitoring: bool = True

@dataclass
class TrainingSchedule:
    name: str
    cron_expression: str
    training_config: TrainingConfiguration
    enabled: bool = True
    priority: int = 1
```

## üèÅ Conclusion

The Self-Play Training Pipeline provides a comprehensive solution for autonomous Battlesnake AI evolution. With proper configuration and monitoring, it enables continuous improvement through sophisticated neural network training and evaluation.

### Key Success Factors

1. **Adequate Resources**: Ensure sufficient RAM, disk space, and GPU memory
2. **Quality Data**: Maintain high-quality training data with diverse strategies
3. **Proper Monitoring**: Regular monitoring prevents issues and optimizes performance
4. **Incremental Deployment**: Start with basic configurations and gradually add complexity
5. **Regular Maintenance**: Update configurations and clean up old data regularly

### Support and Community

- **Issues**: Report issues with detailed logs and system information
- **Performance**: Share benchmark results and optimization tips
- **Integration**: Document successful integrations with other systems
- **Best Practices**: Contribute operational knowledge and troubleshooting solutions

---

**Happy Training! üêçüéØ**

*For technical support, please provide system specifications, configuration files, and relevant log excerpts.*